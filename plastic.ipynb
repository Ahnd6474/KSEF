{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be96a56646559a26",
   "metadata": {},
   "source": [
    "# Plastic Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feaf6ce639fffd7",
   "metadata": {},
   "source": [
    "We attempt to design new plastic molecule using LDM.\n",
    "Our main goal is on\n",
    "1. Straw\n",
    "2. ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba3d462540fb66",
   "metadata": {},
   "source": [
    "## Setup enviroment\n",
    "!git clone https://github.com/Ahnd6474/KSEF\n",
    "\n",
    "%cd your_shit/GitHub/KSEF\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c1e0914dd7ef6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:54:08.371827Z",
     "start_time": "2025-11-19T23:54:08.364039Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Iterator, Optional\n",
    "import pyarrow\n",
    "import torch\n",
    "from geoldm.configs import get_dataset_info\n",
    "from geoldm.qm9 import dataset, load_model, sampling, visualize_molecule_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b80a769160d02",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bb23c5d1539f3ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:54:10.278984Z",
     "start_time": "2025-11-19T23:54:08.386184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp</th>\n",
       "      <th>Tg</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Td</th>\n",
       "      <th>YM</th>\n",
       "      <th>TS_y</th>\n",
       "      <th>TS_b</th>\n",
       "      <th>eps_b</th>\n",
       "      <th>perm_O2</th>\n",
       "      <th>perm_CO2</th>\n",
       "      <th>perm_He</th>\n",
       "      <th>perm_N2</th>\n",
       "      <th>perm_CH4</th>\n",
       "      <th>perm_H2</th>\n",
       "      <th>smiles</th>\n",
       "      <th>num_side</th>\n",
       "      <th>num_back</th>\n",
       "      <th>end_group</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>246.341049</td>\n",
       "      <td>354.051544</td>\n",
       "      <td>524.699646</td>\n",
       "      <td>773.208252</td>\n",
       "      <td>25.838213</td>\n",
       "      <td>32.409279</td>\n",
       "      <td>103.836082</td>\n",
       "      <td>-0.074397</td>\n",
       "      <td>-0.109570</td>\n",
       "      <td>0.493981</td>\n",
       "      <td>-0.071000</td>\n",
       "      <td>-0.061771</td>\n",
       "      <td>0.296051</td>\n",
       "      <td>[[*]OCCC(=O)[*], [*]OCCC(=O)[*]]</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[3.0, 3.0]</td>\n",
       "      <td>[, ]</td>\n",
       "      <td>[pha, pha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>313.798401</td>\n",
       "      <td>449.257751</td>\n",
       "      <td>502.616241</td>\n",
       "      <td>1866.776855</td>\n",
       "      <td>44.379429</td>\n",
       "      <td>38.010651</td>\n",
       "      <td>7.215131</td>\n",
       "      <td>-0.043089</td>\n",
       "      <td>-0.006026</td>\n",
       "      <td>0.462577</td>\n",
       "      <td>-0.049233</td>\n",
       "      <td>-0.031425</td>\n",
       "      <td>0.342873</td>\n",
       "      <td>[[*]OCCC(=O)[*], [*]OC(O)CC(=O)[*]]</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[3.0, 3.0]</td>\n",
       "      <td>[, O]</td>\n",
       "      <td>[pha, pha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>306.681305</td>\n",
       "      <td>446.618713</td>\n",
       "      <td>502.605896</td>\n",
       "      <td>1769.267456</td>\n",
       "      <td>44.743877</td>\n",
       "      <td>37.998493</td>\n",
       "      <td>8.727348</td>\n",
       "      <td>-0.050900</td>\n",
       "      <td>-0.028856</td>\n",
       "      <td>0.455602</td>\n",
       "      <td>-0.060321</td>\n",
       "      <td>-0.039934</td>\n",
       "      <td>0.322175</td>\n",
       "      <td>[[*]OCCC(=O)[*], [*]OC(O)CC(=O)[*]]</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[3.0, 3.0]</td>\n",
       "      <td>[, O]</td>\n",
       "      <td>[pha, pha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>298.431488</td>\n",
       "      <td>442.813019</td>\n",
       "      <td>503.664642</td>\n",
       "      <td>1653.973633</td>\n",
       "      <td>44.287182</td>\n",
       "      <td>37.676380</td>\n",
       "      <td>10.997544</td>\n",
       "      <td>-0.057812</td>\n",
       "      <td>-0.048113</td>\n",
       "      <td>0.458959</td>\n",
       "      <td>-0.069126</td>\n",
       "      <td>-0.047438</td>\n",
       "      <td>0.314363</td>\n",
       "      <td>[[*]OCCC(=O)[*], [*]OC(O)CC(=O)[*]]</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[3.0, 3.0]</td>\n",
       "      <td>[, O]</td>\n",
       "      <td>[pha, pha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>290.073944</td>\n",
       "      <td>436.398560</td>\n",
       "      <td>505.013275</td>\n",
       "      <td>1508.705688</td>\n",
       "      <td>42.840149</td>\n",
       "      <td>36.907192</td>\n",
       "      <td>14.239414</td>\n",
       "      <td>-0.065853</td>\n",
       "      <td>-0.065725</td>\n",
       "      <td>0.461121</td>\n",
       "      <td>-0.075789</td>\n",
       "      <td>-0.055182</td>\n",
       "      <td>0.302125</td>\n",
       "      <td>[[*]OCCC(=O)[*], [*]OC(O)CC(=O)[*]]</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[3.0, 3.0]</td>\n",
       "      <td>[, O]</td>\n",
       "      <td>[pha, pha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>325.252380</td>\n",
       "      <td>462.438263</td>\n",
       "      <td>502.465759</td>\n",
       "      <td>2680.520020</td>\n",
       "      <td>39.839355</td>\n",
       "      <td>68.497833</td>\n",
       "      <td>30.515642</td>\n",
       "      <td>0.011635</td>\n",
       "      <td>-0.060768</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.056135</td>\n",
       "      <td>[[*]CC([*])O, [*]CC([*])O]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[PVA, PVA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>369.788818</td>\n",
       "      <td>509.966248</td>\n",
       "      <td>587.491455</td>\n",
       "      <td>2227.901367</td>\n",
       "      <td>33.554047</td>\n",
       "      <td>37.865055</td>\n",
       "      <td>1.950041</td>\n",
       "      <td>2.547638</td>\n",
       "      <td>11.337365</td>\n",
       "      <td>21.572718</td>\n",
       "      <td>0.559539</td>\n",
       "      <td>0.881040</td>\n",
       "      <td>24.865118</td>\n",
       "      <td>[[*]CC([*])c1ccccc1, [*]CC([*])c1ccccc1]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[PS, PS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373500</th>\n",
       "      <td>0.0</td>\n",
       "      <td>344.375183</td>\n",
       "      <td>457.250885</td>\n",
       "      <td>574.055664</td>\n",
       "      <td>1724.992798</td>\n",
       "      <td>50.262169</td>\n",
       "      <td>46.697941</td>\n",
       "      <td>27.839941</td>\n",
       "      <td>0.099392</td>\n",
       "      <td>0.332474</td>\n",
       "      <td>1.581858</td>\n",
       "      <td>-0.005775</td>\n",
       "      <td>0.070204</td>\n",
       "      <td>1.482780</td>\n",
       "      <td>[[*]CC([*])Cl, [*]CC([*])Cl]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[PVC, PVC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373501</th>\n",
       "      <td>0.0</td>\n",
       "      <td>393.653473</td>\n",
       "      <td>536.671326</td>\n",
       "      <td>700.403137</td>\n",
       "      <td>1942.565186</td>\n",
       "      <td>44.805931</td>\n",
       "      <td>65.647507</td>\n",
       "      <td>27.729816</td>\n",
       "      <td>0.016741</td>\n",
       "      <td>0.138303</td>\n",
       "      <td>1.767082</td>\n",
       "      <td>-0.054595</td>\n",
       "      <td>-0.069961</td>\n",
       "      <td>1.336078</td>\n",
       "      <td>[[*]CCOC(=O)c1ccc2cc(C(=O)O[*])ccc2c1, [*]CCOC...</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[PEN, PEN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373502</th>\n",
       "      <td>0.0</td>\n",
       "      <td>317.276978</td>\n",
       "      <td>469.612549</td>\n",
       "      <td>686.914612</td>\n",
       "      <td>1508.900513</td>\n",
       "      <td>54.058247</td>\n",
       "      <td>40.808701</td>\n",
       "      <td>4.400261</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>-0.059302</td>\n",
       "      <td>0.252653</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.044955</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>[[*]CCCCCC(=O)N[*], [*]CCCCCC(=O)N[*]]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[Nylon6, Nylon6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1373503 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         comp          Tg          Tm          Td           YM       TS_y  \\\n",
       "0         0.0  246.341049  354.051544  524.699646   773.208252  25.838213   \n",
       "1         0.1  313.798401  449.257751  502.616241  1866.776855  44.379429   \n",
       "2         0.2  306.681305  446.618713  502.605896  1769.267456  44.743877   \n",
       "3         0.3  298.431488  442.813019  503.664642  1653.973633  44.287182   \n",
       "4         0.4  290.073944  436.398560  505.013275  1508.705688  42.840149   \n",
       "...       ...         ...         ...         ...          ...        ...   \n",
       "1373498   0.0  325.252380  462.438263  502.465759  2680.520020  39.839355   \n",
       "1373499   0.0  369.788818  509.966248  587.491455  2227.901367  33.554047   \n",
       "1373500   0.0  344.375183  457.250885  574.055664  1724.992798  50.262169   \n",
       "1373501   0.0  393.653473  536.671326  700.403137  1942.565186  44.805931   \n",
       "1373502   0.0  317.276978  469.612549  686.914612  1508.900513  54.058247   \n",
       "\n",
       "              TS_b       eps_b   perm_O2   perm_CO2    perm_He   perm_N2  \\\n",
       "0        32.409279  103.836082 -0.074397  -0.109570   0.493981 -0.071000   \n",
       "1        38.010651    7.215131 -0.043089  -0.006026   0.462577 -0.049233   \n",
       "2        37.998493    8.727348 -0.050900  -0.028856   0.455602 -0.060321   \n",
       "3        37.676380   10.997544 -0.057812  -0.048113   0.458959 -0.069126   \n",
       "4        36.907192   14.239414 -0.065853  -0.065725   0.461121 -0.075789   \n",
       "...            ...         ...       ...        ...        ...       ...   \n",
       "1373498  68.497833   30.515642  0.011635  -0.060768   0.179605  0.002471   \n",
       "1373499  37.865055    1.950041  2.547638  11.337365  21.572718  0.559539   \n",
       "1373500  46.697941   27.839941  0.099392   0.332474   1.581858 -0.005775   \n",
       "1373501  65.647507   27.729816  0.016741   0.138303   1.767082 -0.054595   \n",
       "1373502  40.808701    4.400261 -0.004739  -0.059302   0.252653  0.014024   \n",
       "\n",
       "         perm_CH4    perm_H2  \\\n",
       "0       -0.061771   0.296051   \n",
       "1       -0.031425   0.342873   \n",
       "2       -0.039934   0.322175   \n",
       "3       -0.047438   0.314363   \n",
       "4       -0.055182   0.302125   \n",
       "...           ...        ...   \n",
       "1373498  0.001415   0.056135   \n",
       "1373499  0.881040  24.865118   \n",
       "1373500  0.070204   1.482780   \n",
       "1373501 -0.069961   1.336078   \n",
       "1373502  0.044955   0.000020   \n",
       "\n",
       "                                                    smiles    num_side  \\\n",
       "0                         [[*]OCCC(=O)[*], [*]OCCC(=O)[*]]  [0.0, 0.0]   \n",
       "1                      [[*]OCCC(=O)[*], [*]OC(O)CC(=O)[*]]  [0.0, 0.0]   \n",
       "2                      [[*]OCCC(=O)[*], [*]OC(O)CC(=O)[*]]  [0.0, 0.0]   \n",
       "3                      [[*]OCCC(=O)[*], [*]OC(O)CC(=O)[*]]  [0.0, 0.0]   \n",
       "4                      [[*]OCCC(=O)[*], [*]OC(O)CC(=O)[*]]  [0.0, 0.0]   \n",
       "...                                                    ...         ...   \n",
       "1373498                         [[*]CC([*])O, [*]CC([*])O]  [nan, nan]   \n",
       "1373499           [[*]CC([*])c1ccccc1, [*]CC([*])c1ccccc1]  [nan, nan]   \n",
       "1373500                       [[*]CC([*])Cl, [*]CC([*])Cl]  [nan, nan]   \n",
       "1373501  [[*]CCOC(=O)c1ccc2cc(C(=O)O[*])ccc2c1, [*]CCOC...  [nan, nan]   \n",
       "1373502             [[*]CCCCCC(=O)N[*], [*]CCCCCC(=O)N[*]]  [nan, nan]   \n",
       "\n",
       "           num_back     end_group             names  \n",
       "0        [3.0, 3.0]          [, ]        [pha, pha]  \n",
       "1        [3.0, 3.0]         [, O]        [pha, pha]  \n",
       "2        [3.0, 3.0]         [, O]        [pha, pha]  \n",
       "3        [3.0, 3.0]         [, O]        [pha, pha]  \n",
       "4        [3.0, 3.0]         [, O]        [pha, pha]  \n",
       "...             ...           ...               ...  \n",
       "1373498  [nan, nan]  [None, None]        [PVA, PVA]  \n",
       "1373499  [nan, nan]  [None, None]          [PS, PS]  \n",
       "1373500  [nan, nan]  [None, None]        [PVC, PVC]  \n",
       "1373501  [nan, nan]  [None, None]        [PEN, PEN]  \n",
       "1373502  [nan, nan]  [None, None]  [Nylon6, Nylon6]  \n",
       "\n",
       "[1373503 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_parquet('data/plastic.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb66463e2017a951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:57:34.805872Z",
     "start_time": "2025-11-19T23:57:34.260262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp</th>\n",
       "      <th>Tg</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Td</th>\n",
       "      <th>YM</th>\n",
       "      <th>TS_y</th>\n",
       "      <th>TS_b</th>\n",
       "      <th>eps_b</th>\n",
       "      <th>perm_O2</th>\n",
       "      <th>perm_CO2</th>\n",
       "      <th>perm_He</th>\n",
       "      <th>perm_N2</th>\n",
       "      <th>perm_CH4</th>\n",
       "      <th>perm_H2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "      <td>1.373503e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.997987e-01</td>\n",
       "      <td>2.725839e+02</td>\n",
       "      <td>3.529060e+02</td>\n",
       "      <td>5.769558e+02</td>\n",
       "      <td>5.405507e+02</td>\n",
       "      <td>2.073843e+01</td>\n",
       "      <td>2.460826e+01</td>\n",
       "      <td>2.115185e+02</td>\n",
       "      <td>8.110294e-01</td>\n",
       "      <td>4.332410e+00</td>\n",
       "      <td>7.026700e+00</td>\n",
       "      <td>1.901237e-01</td>\n",
       "      <td>4.661335e-01</td>\n",
       "      <td>7.116223e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.583418e-01</td>\n",
       "      <td>2.701165e+01</td>\n",
       "      <td>3.713276e+01</td>\n",
       "      <td>2.686434e+01</td>\n",
       "      <td>4.882776e+02</td>\n",
       "      <td>1.366027e+01</td>\n",
       "      <td>1.229784e+01</td>\n",
       "      <td>1.205617e+02</td>\n",
       "      <td>8.184573e-01</td>\n",
       "      <td>3.972706e+00</td>\n",
       "      <td>4.018037e+00</td>\n",
       "      <td>2.560846e-01</td>\n",
       "      <td>5.097858e-01</td>\n",
       "      <td>4.612499e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.020853e+02</td>\n",
       "      <td>2.794441e+02</td>\n",
       "      <td>4.246918e+02</td>\n",
       "      <td>9.102757e+01</td>\n",
       "      <td>3.014123e+00</td>\n",
       "      <td>4.558969e+00</td>\n",
       "      <td>4.952888e-01</td>\n",
       "      <td>-9.569907e-02</td>\n",
       "      <td>-1.267213e-01</td>\n",
       "      <td>1.728067e-01</td>\n",
       "      <td>-1.294968e-01</td>\n",
       "      <td>-1.326250e-01</td>\n",
       "      <td>2.026558e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>2.543430e+02</td>\n",
       "      <td>3.266345e+02</td>\n",
       "      <td>5.673138e+02</td>\n",
       "      <td>1.744876e+02</td>\n",
       "      <td>8.976903e+00</td>\n",
       "      <td>1.493889e+01</td>\n",
       "      <td>1.076303e+02</td>\n",
       "      <td>3.791428e-01</td>\n",
       "      <td>1.926220e+00</td>\n",
       "      <td>4.530061e+00</td>\n",
       "      <td>5.799794e-02</td>\n",
       "      <td>1.869081e-01</td>\n",
       "      <td>4.429616e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2.699055e+02</td>\n",
       "      <td>3.456665e+02</td>\n",
       "      <td>5.827677e+02</td>\n",
       "      <td>3.266322e+02</td>\n",
       "      <td>1.742608e+01</td>\n",
       "      <td>2.180278e+01</td>\n",
       "      <td>2.111784e+02</td>\n",
       "      <td>6.681085e-01</td>\n",
       "      <td>3.541990e+00</td>\n",
       "      <td>6.793644e+00</td>\n",
       "      <td>1.420151e-01</td>\n",
       "      <td>3.605243e-01</td>\n",
       "      <td>6.750260e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>2.883478e+02</td>\n",
       "      <td>3.725729e+02</td>\n",
       "      <td>5.933018e+02</td>\n",
       "      <td>7.870456e+02</td>\n",
       "      <td>3.001149e+01</td>\n",
       "      <td>3.317859e+01</td>\n",
       "      <td>3.043738e+02</td>\n",
       "      <td>1.066986e+00</td>\n",
       "      <td>5.741556e+00</td>\n",
       "      <td>9.030967e+00</td>\n",
       "      <td>2.563907e-01</td>\n",
       "      <td>6.126437e-01</td>\n",
       "      <td>9.138975e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>4.033092e+02</td>\n",
       "      <td>5.529254e+02</td>\n",
       "      <td>7.004031e+02</td>\n",
       "      <td>3.081163e+03</td>\n",
       "      <td>7.795893e+01</td>\n",
       "      <td>1.298841e+02</td>\n",
       "      <td>5.666409e+02</td>\n",
       "      <td>3.425747e+01</td>\n",
       "      <td>1.253688e+02</td>\n",
       "      <td>1.188544e+02</td>\n",
       "      <td>8.895615e+00</td>\n",
       "      <td>1.651693e+01</td>\n",
       "      <td>1.671498e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               comp            Tg            Tm            Td            YM  \\\n",
       "count  1.373503e+06  1.373503e+06  1.373503e+06  1.373503e+06  1.373503e+06   \n",
       "mean   4.997987e-01  2.725839e+02  3.529060e+02  5.769558e+02  5.405507e+02   \n",
       "std    2.583418e-01  2.701165e+01  3.713276e+01  2.686434e+01  4.882776e+02   \n",
       "min    0.000000e+00  2.020853e+02  2.794441e+02  4.246918e+02  9.102757e+01   \n",
       "25%    3.000000e-01  2.543430e+02  3.266345e+02  5.673138e+02  1.744876e+02   \n",
       "50%    5.000000e-01  2.699055e+02  3.456665e+02  5.827677e+02  3.266322e+02   \n",
       "75%    7.000000e-01  2.883478e+02  3.725729e+02  5.933018e+02  7.870456e+02   \n",
       "max    9.000000e-01  4.033092e+02  5.529254e+02  7.004031e+02  3.081163e+03   \n",
       "\n",
       "               TS_y          TS_b         eps_b       perm_O2      perm_CO2  \\\n",
       "count  1.373503e+06  1.373503e+06  1.373503e+06  1.373503e+06  1.373503e+06   \n",
       "mean   2.073843e+01  2.460826e+01  2.115185e+02  8.110294e-01  4.332410e+00   \n",
       "std    1.366027e+01  1.229784e+01  1.205617e+02  8.184573e-01  3.972706e+00   \n",
       "min    3.014123e+00  4.558969e+00  4.952888e-01 -9.569907e-02 -1.267213e-01   \n",
       "25%    8.976903e+00  1.493889e+01  1.076303e+02  3.791428e-01  1.926220e+00   \n",
       "50%    1.742608e+01  2.180278e+01  2.111784e+02  6.681085e-01  3.541990e+00   \n",
       "75%    3.001149e+01  3.317859e+01  3.043738e+02  1.066986e+00  5.741556e+00   \n",
       "max    7.795893e+01  1.298841e+02  5.666409e+02  3.425747e+01  1.253688e+02   \n",
       "\n",
       "            perm_He       perm_N2      perm_CH4       perm_H2  \n",
       "count  1.373503e+06  1.373503e+06  1.373503e+06  1.373503e+06  \n",
       "mean   7.026700e+00  1.901237e-01  4.661335e-01  7.116223e+00  \n",
       "std    4.018037e+00  2.560846e-01  5.097858e-01  4.612499e+00  \n",
       "min    1.728067e-01 -1.294968e-01 -1.326250e-01  2.026558e-05  \n",
       "25%    4.530061e+00  5.799794e-02  1.869081e-01  4.429616e+00  \n",
       "50%    6.793644e+00  1.420151e-01  3.605243e-01  6.750260e+00  \n",
       "75%    9.030967e+00  2.563907e-01  6.126437e-01  9.138975e+00  \n",
       "max    1.188544e+02  8.895615e+00  1.651693e+01  1.671498e+02  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5152fb9dcbe4c51d",
   "metadata": {},
   "source": [
    "## Property Prediction\n",
    "We use MLP multi regressor to predict property of plastic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980fc32927142b91",
   "metadata": {},
   "source": [
    "### Load Model and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f282a01a0bf16d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import ast\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
    "from tqdm.auto import tqdm\n",

    "\n",
    "from geoldm import encode, load_model, smiles_to_3d\n",
    "from geoldm.configs import get_dataset_info\n",
    "from geoldm.qm9 import dataset\n",
    "\n",
    "TARGET_COLUMNS = ['Tg', 'Tm', 'Td', 'YM', 'TS_y', 'TS_b', 'eps_b', 'perm_O2', 'perm_CO2', 'perm_He', 'perm_N2', 'perm_CH4', 'perm_H2']\n",
    "\n",
    "\n",
    "def load_qm9_latent_diffusion(checkpoint_dir: Path):\n",
    "    \"\"\"Load a pretrained latent diffusion model and its dataset metadata.\"\"\"\n",
    "\n",
    "    args_path = checkpoint_dir / \"args.pickle\"\n",
    "    with args_path.open(\"rb\") as handle:\n",
    "        args = pickle.load(handle)\n",
    "\n",
    "    # Force CPU execution when CUDA is unavailable.\n",
    "    if not torch.cuda.is_available():\n",
    "        setattr(args, \"cuda\", False)\n",
    "\n",
    "    dataset_info = get_dataset_info(args.dataset, args.remove_h)\n",
    "    dataloaders, _ = dataset.retrieve_dataloaders(args)\n",
    "    train_loader = dataloaders[\"train\"]\n",
    "\n",
    "    model, nodes_dist, _ = load_model(\n",
    "        stage=\"latent_diffusion\",\n",
    "        args=args,\n",
    "        dataset_info=dataset_info,\n",
    "        dataloader_train=train_loader,\n",
    "        checkpoint_path=checkpoint_dir,\n",
    "    )\n",
    "    device = next(model.parameters()).device\n",
    "    return model, dataset_info, nodes_dist, device\n",
    "\n",
    "\n",
    "def _pick_base_smiles(smiles_entry: object) -> str:\n",
    "    \"\"\"Normalize the parquet smiles field to a single SMILES string.\"\"\"\n",
    "\n",
    "    if isinstance(smiles_entry, str):\n",
    "        try:\n",
    "            maybe_list = ast.literal_eval(smiles_entry)\n",
    "        except Exception:\n",
    "            return smiles_entry\n",
    "        if isinstance(maybe_list, (list, tuple, np.ndarray)):\n",
    "            for candidate in maybe_list:\n",
    "                if isinstance(candidate, str):\n",
    "                    return candidate\n",
    "    if isinstance(smiles_entry, (list, tuple, np.ndarray)):\n",
    "        for candidate in smiles_entry:\n",
    "            if isinstance(candidate, str):\n",
    "                return candidate\n",
    "    return str(smiles_entry)\n",
    "\n",
    "\n",
    "def conformer_to_tensors(\n",
    "    conformer: Dict,\n",
    "    dataset_info: Dict,\n",
    "    device: torch.device,\n",
    ") -> Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Convert a single RDKit conformer into GeoLDM-ready tensors.\"\"\"\n",
    "\n",
    "    atom_decoder: List[str] = dataset_info[\"atom_decoder\"]\n",
    "    atom_encoder = {symbol: idx for idx, symbol in enumerate(atom_decoder)}\n",
    "    atom_indices = torch.tensor(\n",
    "        [atom_encoder[symbol] for symbol in conformer[\"atom_symbols\"]],\n",
    "        dtype=torch.long,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    one_hot = F.one_hot(atom_indices, num_classes=len(atom_decoder)).float()\n",
    "    positions = torch.tensor(conformer[\"coordinates\"], dtype=torch.float32, device=device)\n",
    "\n",
    "    # Add batch dimensions and masks.\n",
    "    x = positions.unsqueeze(0)\n",
    "    h = {\n",
    "        \"categorical\": one_hot.unsqueeze(0),\n",
    "        # Use zero charges when absent.\n",
    "        \"integer\": torch.zeros(one_hot.shape[0], 1, device=device).unsqueeze(0),\n",
    "    }\n",
    "\n",
    "    node_mask = torch.ones(x.shape[0], x.shape[1], 1, device=device)\n",
    "    edge_mask = node_mask.squeeze(-1)[..., None] * node_mask.squeeze(-1)[:, None]\n",
    "    return x, h, node_mask, edge_mask\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def smiles_to_latent(\n",
    "    smiles: str,\n",
    "    model: torch.nn.Module,\n",
    "    dataset_info: Dict,\n",
    "    device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Encode a SMILES string into a pooled latent vector using the LDM encoder.\"\"\"\n",
    "\n",
    "    conformers = smiles_to_3d(smiles)\n",
    "    if len(conformers) == 0:\n",
    "        raise ValueError(f\"Failed to build 3D structure for {smiles!r}\")\n",
    "\n",
    "    x, h, node_mask, edge_mask = conformer_to_tensors(conformers[0], dataset_info, device)\n",
    "    z_x, _, z_h, _ = encode(model, x, h, node_mask=node_mask, edge_mask=edge_mask)\n",
    "\n",
    "    pooled_x = z_x.mean(dim=1)\n",
    "    pooled_h = z_h.mean(dim=1)\n",
    "    latent = torch.cat([pooled_x.flatten(), pooled_h.flatten()], dim=-1)\n",
    "    return latent.cpu()\n",
    "\n",
    "\n",
    "def build_latent_matrix(\n",
    "    frame: pd.DataFrame,\n",
    "    model: torch.nn.Module,\n",
    "    dataset_info: Dict,\n",
    "    device: torch.device,\n",
    "    *,\n",
    "    sample_size: int = 512,\n",
    "    cache_path: Optional[Path] = Path(\"data/plastic_latents.pt\"),\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, List[int]]:\n",
    "    \"\"\"Convert a dataframe of plastics into latent vectors and targets.\n",
    "\n",
    "    The helper optionally caches results to avoid recomputation when the notebook\n",
    "    is rerun.\n",
    "    \"\"\"\n",
    "\n",
    "    if cache_path and cache_path.exists():\n",
    "        payload = torch.load(cache_path)\n",
    "        return payload[\"embeddings\"], payload[\"targets\"], payload[\"indices\"]\n",
    "\n",
    "    subset = frame.sample(min(sample_size, len(frame)), random_state=0).reset_index()\n",
    "    embeddings: List[torch.Tensor] = []\n",
    "    targets: List[torch.Tensor] = []\n",
    "    used_indices: List[int] = []\n",
    "\n",
    "    for _, row in tqdm(subset.iterrows(), total=len(subset), desc=\"Encoding SMILES\"):\n",

    "        base_smiles = _pick_base_smiles(row[\"smiles\"])\n",
    "        try:\n",
    "            latent = smiles_to_latent(base_smiles, model, dataset_info, device)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        embeddings.append(latent)\n",
    "        targets.append(torch.tensor(row[TARGET_COLUMNS].values, dtype=torch.float32))\n",
    "        used_indices.append(int(row[\"index\"]))\n",
    "\n",
    "    if not embeddings:\n",
    "        raise RuntimeError(\"No embeddings were created; check SMILES parsing\")\n",
    "\n",
    "    emb_tensor = torch.stack(embeddings)\n",
    "    target_tensor = torch.stack(targets)\n",
    "\n",
    "    if cache_path:\n",
    "        cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(\n",
    "            {\"embeddings\": emb_tensor, \"targets\": target_tensor, \"indices\": used_indices},\n",
    "            cache_path,\n",
    "        )\n",
    "\n",
    "    return emb_tensor, target_tensor, used_indices\n",
    "\n",
    "\n",
    "class MultiTaskMLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        output_dim: int,\n",
    "        hidden_sizes: Iterable[int] = (256, 128),\n",
    "        dropout: float = 0.1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        layers: List[nn.Module] = []\n",
    "        prev = input_dim\n",
    "        for width in hidden_sizes:\n",
    "            layers.extend([nn.Linear(prev, width), nn.ReLU(), nn.Dropout(dropout)])\n",
    "            prev = width\n",
    "        layers.append(nn.Linear(prev, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # noqa: D401\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "def train_multitask_mlp(\n",
    "    embeddings: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    *,\n",
    "    epochs: int = 15,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 1e-3,\n",
    "    validation_split: float = 0.1,\n",
    ") -> Tuple[MultiTaskMLP, StandardScaler, StandardScaler, Dict[str, List[float]]]:\n",
    "    \"\"\"Train a simple multitask MLP on latent embeddings.\"\"\"\n",
    "\n",
    "    x_scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    x_scaled = x_scaler.fit_transform(embeddings)\n",
    "    y_scaled = y_scaler.fit_transform(targets)\n",
    "\n",
    "    features = torch.tensor(x_scaled, dtype=torch.float32)\n",
    "    labels = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(features, labels)\n",
    "    val_size = max(1, int(len(dataset) * validation_split))\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_set, val_set = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "    model = MultiTaskMLP(features.shape[1], labels.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    history = {\"train\": [], \"val\": []}\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training epochs\"):\n",

    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_x)\n",
    "            loss = criterion(preds, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(batch_x)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                preds = model(batch_x)\n",
    "                loss = criterion(preds, batch_y)\n",
    "                val_loss += loss.item() * len(batch_x)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        history[\"train\"].append(train_loss)\n",
    "        history[\"val\"].append(val_loss)\n",
    "\n",
    "    return model, x_scaler, y_scaler, history\n",
    "\n",
    "\n",
    "def predict_properties(\n",
    "    smiles: str,\n",
    "    *,\n",
    "    ldm_model: torch.nn.Module,\n",
    "    dataset_info: Dict,\n",
    "    device: torch.device,\n",
    "    mlp_model: MultiTaskMLP,\n",
    "    x_scaler: StandardScaler,\n",
    "    y_scaler: StandardScaler,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Generate property predictions for a new SMILES string.\"\"\"\n",
    "\n",
    "    latent = smiles_to_latent(smiles, ldm_model, dataset_info, device)\n",
    "    scaled = x_scaler.transform(latent.unsqueeze(0))\n",
    "    mlp_model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_scaled = mlp_model(torch.tensor(scaled, dtype=torch.float32)).cpu().numpy()\n",
    "    pred = y_scaler.inverse_transform(pred_scaled)[0]\n",
    "    return {name: value for name, value in zip(TARGET_COLUMNS, pred)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9945bf64417b01f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:54:10.400722Z",
     "start_time": "2025-11-19T23:54:10.396091Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load pretrained latent diffusion encoder\n",
    "checkpoint_dir = Path(\"./qm9_latent2\")\n",
    "ldm_model, dataset_info, nodes_dist, device = load_qm9_latent_diffusion(checkpoint_dir)\n",
    "\n",
    "# Prepare the plastics dataframe and build (or load) latent embeddings.\n",
    "plastic_df = pd.read_parquet(\"data/plastic.parquet\")\n",
    "embeddings, targets, used_indices = build_latent_matrix(\n",
    "    plastic_df,\n",
    "    ldm_model,\n",
    "    dataset_info,\n",
    "    device,\n",
    "    sample_size=512,  # keep runtime manageable inside the notebook\n",
    "    cache_path=Path(\"data/plastic_latents.pt\"),\n",
    ")\n",
    "\n",
    "# Train the multi-task MLP regressor.\n",
    "mlp_model, x_scaler, y_scaler, history = train_multitask_mlp(\n",
    "    embeddings.numpy(),\n",
    "    targets.numpy(),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    ")\n",
    "\n",
    "print(\"Training loss trajectory:\", history[\"train\"])\n",
    "print(\"Validation loss trajectory:\", history[\"val\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce023d1b200007",
   "metadata": {},
   "source": [
    "## Optimization 1: Straw for Cold Brew\n",
    "Optimization Boundary:\n",
    "\n",
    "Tg: -30\\~10 °C\n",
    "\n",
    "Tm: 120\\~200 °C\n",
    "\n",
    "Td: 250°C 이상\n",
    "\n",
    "YM: 0.8\\~1.8GPa->범위 안에 가두어야 함(1.2 근처)\n",
    "\n",
    "TS_b: 20MPa 이상-> 최대화 대상(2)\n",
    "\n",
    "eps_b : 200\\~1000%->최대화 대상(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0106e06603836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:54:10.537293Z",
     "start_time": "2025-11-19T23:54:10.534685Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Example inference call\n",
    "example_smiles = _pick_base_smiles(plastic_df.loc[0, \"smiles\"])\n",
    "predicted = predict_properties(\n",
    "    example_smiles,\n",
    "    ldm_model=ldm_model,\n",
    "    dataset_info=dataset_info,\n",
    "    device=device,\n",
    "    mlp_model=mlp_model,\n",
    "    x_scaler=x_scaler,\n",
    "    y_scaler=y_scaler,\n",
    ")\n",
    "\n",
    "for name, value in predicted.items():\n",
    "    print(f\"{name}: {value:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
